Ceph 클러스터 유지 및 신규 클러스터 구성, 트러블 슈팅
RKE2 클러스터 유지 및 개선, 운영 트러블 슈팅
Backing service (DB, massage queue) 구축 롼기
온프레미스 환경에 쿠버네티스 에 배보펀 서비스 모니터링 및 운영
###########################################################################################

# Ceph & RKE2 클러스터 운영 상세 시나리오 및 트러블슈팅 예제

온프레미스 환경에서 Ceph 스토리지와 RKE2(Kubernetes) 클러스터를 운영 및 확장, 트러블슈팅하는 상세 시나리오와 실전 명령어 예시입니다.

---

## 1. Ceph 클러스터 운영/확장/트러블슈팅 상세 시나리오

### 1.1 신규 Ceph 클러스터 생성 (cephadm)

```bash
# 1) cephadm 설치 및 초기화
sudo dnf install -y cephadm
sudo cephadm bootstrap --mon-ip <ADMIN_NODE_IP> --cluster-network <CLUSTER_NETWORK_CIDR>

# 2) ceph CLI 환경 적용
sudo cephadm shell
ceph status
```

### 1.2 Ceph 클러스터 노드/디스크 추가

#### 1.2.1 노드(서버) 추가
```bash
# Ceph 관리 노드에서 SSH 키를 신규 노드에 복사
ssh-copy-id <user>@<NEW_NODE_IP>

# 노드 등록
ceph orch host add <NEW_NODE_HOSTNAME> <NEW_NODE_IP>
```

#### 1.2.2 OSD(디스크) 추가
```bash
ceph orch daemon add osd <NEW_NODE_HOSTNAME>:<DISK_PATH>
```

#### 1.2.3 MON/MGR/MDS 등 데몬 추가
```bash
ceph orch daemon add mon <NEW_NODE_HOSTNAME>
ceph orch daemon add mgr <NEW_NODE_HOSTNAME>
ceph orch daemon add mds <NEW_NODE_HOSTNAME> --fs <FS_NAME>
```

### 1.3 Ceph 운영 중 흔한 장애/이슈 및 대처

| 케이스                       | 증상/확인 방법                     | 조치 명령어 예시 |
|------------------------------|--------------------------------------|------------------|
| OSD 장애/Down                | ceph health, ceph osd tree           | ceph osd out <osd_id> <br> 디스크 교체 후 ceph orch daemon add osd ...|
| MON 장애                     | ceph quorum_status                   | ceph orch daemon add mon <HOST> |
| Disk full (PG undersized 등)  | ceph df, ceph health detail          | OSD 추가/확장, 데이터 마이그레이션 |
| Network slow/flap            | ceph -s, ceph health, latency 경고   | 네트워크 점검, 재배치 |
| Pool/PG 오류/불균형          | ceph pg dump, ceph balancer status   | ceph balancer on <br> ceph pg repair <pg_id>|
| 인증 관련 문제               | ceph auth list, ceph auth get ...    | ceph auth update ... |
| RBD 마운트/CSI 장애          | K8s PVC 상태, ceph -s                | 로그확인, ceph osd map <image>, csi driver 재시작 |

---

## 2. RKE2 클러스터 운영/확장/트러블슈팅 상세 시나리오

### 2.1 마스터/워커 노드 추가

#### 2.1.1 워커노드 추가
```bash
# 1) RKE2 에이전트 설치
curl -sfL https://get.rke2.io | sudo sh -

# 2) config.yaml 작성 (토큰/마스터 주소)
sudo mkdir -p /etc/rancher/rke2/
echo "server: https://<MASTER_IP>:9345" | sudo tee -a /etc/rancher/rke2/config.yaml
echo "token: <MASTER_NODE_TOKEN>" | sudo tee -a /etc/rancher/rke2/config.yaml

# 3) 서비스 시작
sudo systemctl enable rke2-agent --now
```

#### 2.1.2 마스터노드 추가
```bash
# 1) RKE2 서버 설치 및 config.yaml 설정
curl -sfL https://get.rke2.io | sudo sh -
sudo mkdir -p /etc/rancher/rke2/
echo "server: https://<EXISTING_MASTER_IP>:9345" | sudo tee -a /etc/rancher/rke2/config.yaml
echo "token: <MASTER_NODE_TOKEN>" | sudo tee -a /etc/rancher/rke2/config.yaml
echo "node-taint: ''" | sudo tee -a /etc/rancher/rke2/config.yaml  # taint 해제(선택)

# 2) 서비스 시작
sudo systemctl enable rke2-server --now
```

### 2.2 운영 중 흔한 장애/이슈 및 시나리오

| 케이스                        | 증상/확인 방법                       | 조치/명령 예시 |
|-------------------------------|--------------------------------------|----------------|
| 노드 NotReady                 | kubectl get nodes                    | 로그확인: journalctl -u rke2-agent <br> 네트워크/시간 동기화 확인, 서비스 재기동 |
| Pod CrashLoopBackOff          | kubectl get pods -A                  | kubectl logs <pod> <br> kubectl describe pod <pod> <br> 환경변수, 이미지, 스토리지 점검 |
| 노드 장애/교체                | NotReady 지속                        | kubectl drain <노드> --ignore-daemonsets <br> kubectl delete node <노드> <br> 신규 워커 추가 |
| 컨트롤 플레인 장애            | API 서버 접속 불가                   | 남은 마스터로 이중화, 장애 노드 복구/재설치 |
| CNI/네트워크 장애             | Pod 간 통신 불가/Node NotReady        | CNI Pod 로그확인, 네트워크 설정 점검, 서비스 재기동 |
| cert 갱신/오류                | 인증서 만료/접근 오류                 | rke2-cert-renew(스크립트) 실행, 서비스 재시작 |
| etcd 용량/장애                | 디스크 Full, etcd unhealthy           | etcdctl snapshot, cleanup, 디스크 증설 |

---

## 3. Ceph + RKE2 통합 운영 시나리오

### 3.1 RKE2에 ceph-csi 연동

```yaml
# ceph-csi secret 생성
kubectl create secret generic ceph-secret \
  --from-literal=userID=<ceph-user> --from-literal=userKey=<ceph-key> -n kube-system

# StorageClass 예시
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: ceph-rbd
provisioner: rbd.csi.ceph.com
parameters:
  ...
```

### 3.2 PVC 장애 대응

- PVC Pending: ceph-csi logs, ceph status, StorageClass/Secret 확인
- PVC Lost/ReadOnly: ceph osd, rbd status, pod 재배포

---

## 4. 실제 장애/운영 시나리오 예시

### [Case 1] OSD 장애 및 복구

1. 장애 감지: ceph health, ceph osd tree
2. OSD out 처리: ceph osd out <osd_id>
3. 물리 디스크 교체
4. OSD 재등록: ceph orch daemon add osd <hostname>:<disk>
5. 상태 점검: ceph health

### [Case 2] 노드 NotReady 및 교체

1. 장애 노드 drain: kubectl drain <노드명> --ignore-daemonsets
2. 클러스터에서 노드 삭제: kubectl delete node <노드명>
3. 신규 워커/마스터 노드 추가 (위 명령 참고)
4. 서비스 정상화 확인: kubectl get nodes

### [Case 3] Pod CrashLoopBackOff

1. 로그 확인: kubectl logs <pod> -n <namespace>
2. 환경/리소스/이미지/스토리지 점검
3. 필요시 pod 재배포, pvc 교체

---

## 5. Ceph & RKE2 운영 체크리스트

- [ ] 주기적 ceph health, osd tree, df 체크
- [ ] 주기적 kubectl get nodes, pods -A, event 확인
- [ ] 모니터링/알림 (Prometheus, Alertmanager, Grafana)
- [ ] 주기적 백업 (etcd, ceph snapshot)
- [ ] 보안패치/업데이트 관리
- [ ] 장애시 매뉴얼 및 runbook 문서화

---

# Ceph & RKE2 운영 중 자주 발생하는 다양한 장애/이슈 및 증상별 해결 커멘드

온프레미스 Ceph 및 RKE2 클러스터에서 실무에서 마주칠 수 있는 다양한 장애 유형, 증상, 그리고 즉각적으로 사용할 수 있는 해결 명령어 예시를 정리합니다.

---

## 1. Ceph 운영 중 자주 발생하는 장애/이슈

| 장애/이슈                           | 증상/확인 방법                                       | 원인                              | 해결/조치 커멘드/설명 |
|--------------------------------------|------------------------------------------------------|-----------------------------------|-----------------------|
| OSD Down/Out                         | ceph -s, ceph osd tree, ceph health                  | 디스크 불량, 네트워크 장애        | ceph osd out <id><br>교체 후 ceph orch daemon add osd ... |
| MON Down                             | ceph -s, ceph quorum_status                          | 노드 장애, 프로세스 중단          | ceph orch daemon add mon <HOST> <br> 필요한 경우 ceph orch daemon rm mon.<id> |
| MGR Down                             | ceph -s                                              | 프로세스 장애/메모리 부족         | ceph orch daemon add mgr <HOST> |
| PG stuck/inactive/undersized         | ceph health detail, ceph pg dump                     | OSD 장애, 적은 OSD 수             | OSD 복구/추가, ceph pg repair <pg_id> |
| Full OSD (OSD full)                  | ceph df, ceph -s                                     | 데이터 증가                       | 디스크 추가, ceph osd reweight-by-utilization |
| 클러스터 네트워크 장애               | ceph health, ping, ifconfig                          | NIC 장애, Switch 문제             | 네트워크 점검, ifdown/ifup, 장비 교체 |
| 인증 오류 (keyring, caps)            | ceph auth list, ceph auth get <user>                 | keyring 만료, 권한 불일치         | ceph auth update <user> ..., ceph auth import ... |
| RBD 마운트 오류                      | rbd map, dmesg, ceph log                             | 권한, 네트워크, OSD 장애           | ceph log, rbd status, rbd unmap/map |
| Ceph CSI 에러 (PVC Pending 등)        | kubectl get pvc, describe pvc, ceph status           | secret/StorageClass 오류, CSI Pod 장애 | Secret/StorageClass 점검, CSI Pod 재시작 |
| 스냅샷/복제 오류                     | ceph snap ls, ceph status                            | 공간 부족, 권한 문제               | 공간 확보, ceph auth update, 스냅샷 정리 |

---

## 2. RKE2 운영 중 자주 발생하는 장애/이슈

| 장애/이슈                              | 증상/확인 방법                          | 원인                            | 해결/조치 커멘드/설명 |
|-----------------------------------------|-----------------------------------------|---------------------------------|-----------------------|
| Node NotReady                           | kubectl get nodes                       | 네트워크 문제, kubelet 장애      | journalctl -u rke2-agent<br>systemctl restart rke2-agent<br>시간 동기화/네트워크 점검 |
| Pod CrashLoopBackOff                    | kubectl get pods -A, logs, describe     | 환경변수/이미지/리소스 문제      | kubectl logs, kubectl describe pod, 리소스 할당/이미지 확인 |
| CoreDNS NotReady/서비스 내부 DNS 장애   | kubectl get pods -n kube-system         | CoreDNS 장애, 네트워크 문제      | kubectl rollout restart deployment coredns -n kube-system |
| CNI 네트워크 장애                       | Pod 간 통신불가, NotReady               | CNI Pod 장애, 네트워크 설정      | kubectl get pods -n kube-system<br>CNI Pod 재시작 |
| etcd 용량/장애                          | etcd unhealthy, 디스크 Full             | 로그 누적, 백업 미설정           | etcdctl snapshot save, old snapshot 삭제, 디스크 증설 |
| 인증서 만료/오류                        | API 서버 접속불가                       | cert 만료                        | rke2 cert renew, systemctl restart rke2-server |
| PersistentVolume(PV) 상태 이상          | kubectl get pv, pvc                     | Ceph/CSI 문제, PVC 바인딩 실패   | PVC/StorageClass/Secret 점검, pod/pvc 재생성 |
| Kubelet/컨테이너 런타임 장애            | 노드 NotReady, pod scheduling 실패       | 런타임/디스크/메모리 문제        | systemctl restart rke2-agent/containerd |
| API server 연결 불가                     | kubectl 명령어 실패                     | 방화벽, 인증서, API server 다운   | 포트/방화벽 점검, systemctl restart rke2-server |
| 노드 drain 불가                         | kubectl drain 실패, evict 불가           | DaemonSet, pod disruption budget | --ignore-daemonsets, PDB 점검 |

---

## 3. 복합 장애 예시와 해결 시퀀스

### [A] Ceph OSD 장애 + PVC ReadOnly
1. ceph -s, ceph osd tree로 장애 OSD 확인
2. ceph osd out <id> 처리, 디스크 교체
3. ceph orch daemon add osd <노드>:<디스크>
4. PVC 상태 점검, 필요시 pod 재배포

### [B] RKE2 워커노드 NotReady + Pod Pending
1. kubectl get nodes, describe node로 상태 확인
2. systemctl restart rke2-agent (노드에서)
3. 해결 안되면 drain/delete node, 신규 노드 추가

### [C] Ceph CSI 문제로 PVC Pending
1. kubectl describe pvc, csi pod 로그 확인
2. ceph status, secret/StorageClass 확인
3. CSI Pod 재시작: kubectl delete pod -l app=ceph-csi -n kube-system

---

## 4. 체크리스트

- [ ] 장애 발생 시 로그(ceph, kubelet, csi, etcd, pod 등) 우선 확인
- [ ] 문제 발생 리소스의 상태·이벤트 describe로 확인
- [ ] 명령 실행 전 장애노트, 변경내역 기록 필수
- [ ] 모니터링 및 알림 시스템으로 사전 감지 체계 유지

---


####################################################################################

Ceph 운영 시 흔히 발생하는 상황과 이에 대한 명령어 및 스크립트는 다음과 같습니다.

I. 클러스터 상태 및 상태 모니터링
전반적인 클러스터 상태 확인:

ceph status 또는 ceph -s: 클러스터의 상태(예: HEALTH_OK, HEALTH_WARN, HEALTH_ERR), 서비스 상태(모니터, 관리자, OSD, MDS, RGW), 데이터 사용량, 풀 정보 및 PG 상태에 대한 간략한 개요를 제공합니다. 관리자가 가장 먼저 실행하는 명령입니다.
ceph -w 또는 ceph --watch-warn: 클러스터 활동 및 이벤트를 지속적으로 감시하고 실시간 업데이트를 표시합니다. ceph --watch-warn은 특히 경고 메시지를 필터링합니다.
ceph health: 클러스터 상태 요약을 표시합니다.
ceph health detail: 클러스터가 HEALTH_OK가 아닌 경우 자세한 오류 정보를 제공합니다.
클러스터 사용량 통계 확인:

ceph df: Unix df 명령과 유사하게 총 스토리지 용량, 사용된 공간, 사용 가능한 공간 및 풀 간 사용량 분석을 보여줍니다.
ceph df detail: 할당량 및 압축 사용량을 포함한 풀 통계에 대한 자세한 정보를 제공합니다.
데몬 상태 모니터링:

ceph osd stat: OSD가 up(실행 중이고 연결 가능) 및 in(서비스 중)인지 확인합니다.
ceph mon stat: 선택 에포크 및 쿼럼을 포함한 모니터 데몬의 상태를 표시합니다.
ceph mgr stat: 관리자 데몬의 상태를 표시합니다.
ceph mds stat: CephFS 클러스터에서 메타데이터 서버(MDS)의 상태를 표시합니다.
II. OSD(객체 스토리지 데몬) 관리
OSD 상태 분석:

ceph osd tree: 모든 OSD, 해당 클래스, 가중치, 상태(업/다운, 인/아웃) 및 CRUSH 맵 내 위치의 계층적 보기를 표시합니다. 실패한 OSD와 해당 물리적 위치를 식별하는 데 중요합니다.
ceph osd df tree: CRUSH 트리와 함께 OSD 디스크 사용량을 제공합니다.
ceph osd utilization: OSD에서 사용량 요약(최대 및 최소)을 표시합니다.
ceph osd perf: 커밋 지연 시간과 같은 OSD 성능 메트릭을 확인합니다.
OSD 추가/제거:

ceph osd create: 클러스터에 새 OSD를 추가하는 데 사용됩니다.
ceph osd rm <osd-id>: CRUSH 맵에서 OSD를 제거합니다.
ceph osd out <osd-id>: 클러스터에서 OSD를 out으로 표시하여 Ceph에 해당 OSD에서 데이터를 마이그레이션하도록 신호를 보냅니다.
ceph osd in <osd-id>: 클러스터에서 OSD를 in으로 표시합니다.
ceph osd down <osd-id>: OSD를 down으로 표시합니다.
OSD 가중치 및 플래그 조정:

ceph osd crush reweight <osd-id> <weight>: 데이터 분포를 제어하기 위해 CRUSH 맵에서 OSD의 가중치를 조정합니다. 클러스터의 균형을 맞추거나 용량이 다른 OSD를 수용하는 데 유용합니다.
ceph osd set <flag> / ceph osd unset <flag>: 전역 OSD 플래그를 관리합니다. 일반적인 플래그는 다음과 같습니다.
noout: 유지 관리 중에 자주 사용되며, Ceph가 OSD가 실패할 때 out으로 표시하지 않도록 합니다.
nobackfill: 백필 작업을 비활성화합니다.
norecover: 복구 작업을 비활성화합니다.
norebalance: 재조정 작업을 비활성화합니다.
pauserd, pausewr: OSD에 대한 읽기 및 쓰기 요청을 일시 중지합니다.
ceph osd set-full-ratio <ratio>: 클러스터의 전체 비율을 설정합니다(예: 90%는 0.90).
ceph osd set-nearfull-ratio <ratio>: 클러스터의 거의 전체 비율을 설정합니다(예: 85%는 0.85).
III. 배치 그룹(PG) 관리
PG 상태 확인:

ceph pg dump: 모든 배치 그룹에 대한 자세한 통계를 제공합니다.
ceph pg stat: PG 상태 및 개수를 요약합니다.
ceph pg dump_stuck <state>: 특정 상태(예: inactive, unclean, stale)에 멈춰 있는 PG를 나열합니다.
ceph pg map <pg-id>: 특정 PG가 OSD에 매핑되는 방식을 보여줍니다.
PG 작업 관리:

ceph pg scrub <pg-id>: 데이터 무결성을 확인하기 위해 특정 PG에서 스크럽 작업을 시작합니다.
ceph pg deep-scrub <pg-id>: 더 철저한 데이터 무결성 검사를 위해 정밀 스크럽을 시작합니다.
ceph pg force-recovery <pg-id>: 지정된 PG에 대한 복구를 우선시합니다.
ceph pg force-backfill <pg-id>: 지정된 PG에 대한 백필을 우선시합니다.
ceph osd pool set <pool-name> pg_autoscale_mode <mode>: 지정된 풀(on, off, warn)에 대한 PG의 자동 크기 조정을 제어합니다.
IV. 풀 관리
풀 나열 및 검사:

ceph osd lspools: 구성된 모든 풀을 나열합니다.
ceph osd pool ls detail: 복제 크기, PG 번호 및 CRUSH 규칙을 포함한 풀에 대한 자세한 정보를 제공합니다.
ceph osd pool stats <pool-name>: 특정 풀에 대한 사용량 통계를 표시합니다.
rados df: RADOS 풀 사용량 요약을 제공합니다.
풀 생성 및 삭제:

ceph osd pool create <pool-name> <pg-num> [<pgp-num>] [replicated|erasure]: 새 풀을 생성합니다.
ceph osd pool delete <pool-name> [<pool-name> --yes-i-really-really-mean-it]: 풀을 삭제합니다. 참고: 풀을 삭제하려면 mon_allow_pool_delete가 true여야 합니다.
ceph osd pool rename <old-name> <new-name>: 풀의 이름을 바꿉니다.
풀 설정 구성:

ceph osd pool set <pool-name> <key> <value>: 복제 크기, min_size 또는 애플리케이션 연결과 같은 다양한 풀 매개변수를 설정합니다.
ceph osd pool get <pool-name> <key>: 풀의 구성 값을 검색합니다.
ceph osd pool set-quota <pool-name> max_objects <num> 또는 max_bytes <num>: 풀의 객체 또는 바이트에 대한 할당량을 설정합니다.

V. CRUSH 맵 관리
CRUSH 맵은 데이터가 OSD, 랙 및 기타 장애 도메인에 분산되는 방식을 정의합니다.

CRUSH 맵 보기:

ceph osd tree: CRUSH 계층 구조를 보여줍니다.
ceph osd crush dump: 전체 CRUSH 맵을 덤프합니다.
crushtool -d <컴파일된 맵> -o <디컴파일된 맵.txt>: 편집을 위해 CRUSH 맵 바이너리를 디컴파일합니다.
CRUSH 맵 요소 수정:

ceph osd crush add-bucket <버킷 이름> <버킷 유형>: CRUSH 맵에 새 버킷(예: 호스트, 랙, 행)을 추가합니다.
ceph osd crush move <버킷 이름> <유형>=<위치>: CRUSH 계층 구조 내에서 버킷을 이동합니다.
ceph osd crush set <osd-이름> <가중치> root=<루트> [<버킷 유형>=<버킷 이름> ...]: CRUSH 맵 내에 OSD를 추가하거나 이동합니다.
ceph osd crush set-device-class <클래스> <osd-이름>: CRUSH 규칙에서 사용할 수 있는 장치 클래스(예: ssd, hdd, nvme)를 OSD에 할당합니다.
VI. 인증 및 구성
액세스 및 구성 설정 관리.

인증:
ceph auth list: 클라이언트 및 데몬에 대한 모든 인증 키를 나열합니다.
ceph auth print-key <엔티티>: 특정 엔티티(예: client.admin, osd.0)에 대한 키를 인쇄합니다.
구성:
ceph config dump: 전체 클러스터 구성 데이터베이스를 덤프합니다.
ceph config set <누구> <옵션> <값>: 특정 데몬 또는 전체 클러스터에 대한 구성 옵션을 설정합니다.
ceph config get <누구> <옵션>: 구성 옵션을 검색합니다.
ceph tell <데몬 유형>.<id> config set <옵션> <값>: 특정 데몬에 대한 런타임 구성을 설정합니다.
VII. 재해 복구 및 문제 해결
장애 또는 불일치가 발생한 경우 특정 명령이 복구 및 진단에 도움이 됩니다.

일반적인 문제 해결:

ceph crash ls: 클러스터에 기록된 충돌 이벤트를 나열합니다.
ceph log last [n]: 클러스터 로그에서 마지막 n줄을 표시합니다.
ceph -c /경로/ceph.conf -k /경로/키링 <명령>: 기본이 아닌 구성 및 키링 경로를 지정합니다.
CephFS 복구(고급):

cephfs-journal-tool journal export <backup.bin>: 위험한 작업을 시도하기 전에 백업을 위해 CephFS 저널을 내보냅니다.
cephfs-journal-tool event recover_dentries summary: 손상된 저널에서 파일 메타데이터를 복구하려고 시도합니다.
cephfs-data-scan pg_files <경로> <pg-id> [...]: 손실된 데이터 PG의 영향을 받는 파일을 검색합니다.
ceph fs new <fs_name> <metadata_pool> <data_pool> --force --recover: 모니터 저장소 손실 후 기존 풀에서 CephFS 파일 시스템을 다시 만듭니다.
느리거나 멈춘 OSD 또는 PG 처리:

이러한 항목을 식별하는 것은 종종 ceph status, ceph osd tree 및 ceph pg dump_stuck으로 시작합니다.
ceph pg force-recovery 또는 ceph osd reweight와 같은 명령은 문제를 완화하는 데 도움이 될 수 있습니다.
VIII. 자동화 및 스크립팅
이러한 명령의 대부분은 자동화를 위해 스크립트에 통합될 수 있습니다.

셸 스크립팅: ceph 명령을 grep, awk, jq(ceph -s -f json 또는 ceph pg dump --format=json과 같은 명령의 JSON 출력용)와 파이프하여 특정 정보를 추출하거나 클러스터 상태에 따라 작업을 자동화할 수 있습니다.
ceph-volume: 이 도구는 특히 자동화된 설정에서 OSD 배포 및 관리에 사용되지만 종종 cephadm 또는 rook과 같은 오케스트레이터와 통합됩니다.
rados 명령: 벤치마킹 또는 특정 데이터 작업(rados bench, rados put, rados get)에 유용한 RADOS 객체 저장소와 직접 상호 작용하기 위한 저수준 유틸리티입니다.


###################################################################################################################


1. 상태 확인 및 모니터링:

간단한 상태 확인 스크립트(Bash):
bash
#!/bin/bash
HEALTH=$(ceph health)
if [ "$HEALTH" != 'HEALTH_OK' ]; then
    echo "Ceph 클러스터 상태가 정상이 아닙니다. $HEALTH"
    ceph health detail # 추가 정보 제공
    # 여기에 알림 메커니즘 추가(예: 이메일, Slack 알림)
else
    echo "Ceph 클러스터 상태가 정상입니다."
fi
OSD 및 사용량 모니터링(Bash):
bash
#!/bin/bash
echo "Ceph 클러스터 상태:"
ceph status
echo ""
echo "OSD 트리:"
ceph osd tree
echo ""
echo "OSD 디스크 사용량:"
ceph osd df
echo ""
echo "풀 통계:"
ceph df
2. 유지 관리 모드 스크립트:

유지 관리 시작/종료(Bash):
bash
#!/bin/bash
ACTION=$1 # "start" 또는 "stop"
if [ "$ACTION" = "start" ]; then
    echo "Ceph 클러스터 유지 관리 모드를 시작합니다..."
    ceph osd set noout
    ceph osd set nobackfill
    ceph osd set norecover
    echo "Ceph 유지 관리 플래그(noout, nobackfill, norecover)가 설정되었습니다."
elif [ "$ACTION" = "stop" ]; then
    echo "Ceph 클러스터 유지 관리 모드를 종료합니다..."
    ceph osd unset noout
    ceph osd unset nobackfill
    ceph osd unset norecover
    echo "Ceph 유지 관리 플래그가 해제되었습니다."
else
    echo "사용법: $0 [start|stop]"
    exit 1
fi
3. OSD 관리:

점진적 OSD 재가중치 부여(Python/Bash 조합): ceph-gentle-reweight와 같은 도구(일반적으로 커뮤니티 스크립트 저장소에서 찾을 수 있음)는 CRUSH 가중치를 점진적으로 조정하여 OSD를 천천히 비우고 성능 영향을 최소화할 수 있습니다. 이러한 스크립트는 일반적으로 Ceph CLI와 상호 작용하여 OSD 상태를 쿼리하고 가중치를 업데이트합니다.

OSD 추가(개념적 Bash - 단순화):

bash
#!/bin/bash
DEVICE="/dev/sdb"
HOST="ceph-node1"
echo "$HOST 호스트의 $DEVICE에 OSD를 추가합니다..."
# 이는 단순화된 표현입니다. 실제 시나리오에서는 cephadm 또는 Rook을 사용하는 것이 좋습니다.
# cephadm osd create --data $DEVICE # cephadm을 사용한 예
# 자세한 단계에는 디스크 준비, OSD 배포 및 CRUSH 맵에 추가가 포함됩니다.
echo "$DEVICE에 대한 OSD 배포가 시작되었습니다."
4. 풀 관리:

복제된 풀 생성(Bash):
bash
#!/bin/bash
POOL_NAME="my_replicated_pool"
PG_NUM=128
REPLICAS=3 # 기본 복제본 수
echo "$PG_NUM PG 및 $REPLICAS 복제본으로 복제된 풀 $POOL_NAME을 생성합니다."
ceph osd pool create $POOL_NAME $PG_NUM $PG_NUM replicated
ceph osd pool set $POOL_NAME size $REPLICAS
ceph osd pool application enable $POOL_NAME rbd # 예: RBD에 대해 활성화
echo "풀 $POOL_NAME이 성공적으로 생성되었습니다."


1. 심화된 아키텍처 이해 및 문제 해결:

CRUSH 맵 분석 및 조정: ceph osd crush dump, ceph osd tree, ceph osd crush rule ls, ceph osd crush rule dump 명령어를 사용하여 CRUSH 맵을 분석하고, 필요에 따라 rule을 수정하여 데이터 분산 및 복제 정책을 변경합니다. 예를 들어 특정 장애 도메인에 데이터가 편중되는 것을 방지하기 위해 rule을 조정할 수 있습니다.
OSD 관리 및 장애 복구: ceph osd ls, ceph osd df, ceph osd perf, ceph osd out, ceph osd in, ceph osd rm, ceph osd reweight 명령어를 사용하여 OSD 상태를 확인하고, 장애 발생 시 OSD를 제거하고 추가하며, 가중치를 조정하여 데이터 복제 및 복구를 관리합니다. OSD의 성능 문제를 파악하고 해결할 수 있어야 합니다.
MON 및 MGR 관리: ceph mon stat, ceph mon dump, ceph mgr dump, ceph mgr module ls 명령어를 사용하여 MON 및 MGR 상태를 확인하고, quorum 상태를 유지하며, 모듈을 관리합니다. MON 장애 복구 절차를 숙지하고, MGR을 통해 클러스터 상태를 모니터링하고 관리합니다.
2. 고급 Ceph 기능 활용:

Cache Tiering: SSD와 HDD를 함께 사용하여 성능과 용량을 최적화하는 Cache Tiering을 구성하고 관리합니다. ceph osd tier add, ceph osd tier remove, ceph osd tier cache-mode 명령어를 사용합니다. 캐시 적중률, 지연 시간 등을 모니터링하고 성능을 분석합니다.
Erasure Coding: 데이터 복제 대신 Erasure Coding을 사용하여 저장 공간 효율성을 높입니다. ceph osd pool set <pool-name> erasure_code_profile <profile-name> 명령어를 사용하여 pool에 Erasure Coding을 적용하고, ceph osd erasure-code-profile set <profile-name> <k=m=...> 명령어를 사용하여 profile을 설정합니다. Erasure Coding의 장단점을 이해하고 적절한 use case에 적용합니다.
QoS (Quality of Service): RBD 이미지 또는 CephFS에 QoS를 적용하여 특정 애플리케이션의 성능을 보장합니다. rbd QoS set, ceph fs subvolumegroup set 명령어를 사용합니다.
CephFS Snapshots 및 Quotas: ceph fs subvolume snapshot create, ceph fs subvolume snapshot ls, ceph fs subvolume snapshot rm, ceph fs quota set 명령어를 사용하여 CephFS 스냅샷 및 quota를 관리하고, 데이터 보호 및 용량 관리 정책을 구현합니다.
3. 성능 튜닝 및 최적화:

OSD 성능 튜닝: ceph osd crush tunables 명령어를 사용하여 CRUSH 맵의 튜닝 가능한 파라미터를 조정하고 데이터 분산을 최적화합니다. OSD의 file system, journal, data 디바이스를 분리하여 성능을 향상시키는 방법을 이해하고 적용합니다.
MON 및 MGR 성능 튜닝: MON 및 MGR의 설정을 조정하여 성능 병목 현상을 해결합니다. MON의 네트워크 설정, MGR 모듈 설정 등을 최적화합니다.
네트워크 설정 최적화: MTU, network bonding, multiple network interfaces 등을 설정하여 Ceph 클러스터의 네트워크 성능을 향상시킵니다.
4. Ceph 클러스터 업그레이드 및 관리:

업그레이드 절차: ceph versions, ceph osd upgrade 명령어를 사용하여 Ceph 클러스터를 업그레이드합니다. 업그레이드 절차를 숙지하고, 롤백 계획을 수립하여 안전하게 업그레이드를 수행합니다.
Multi-site deployments: 여러 지역에 Ceph 클러스터를 구축하고 관리합니다. RBD mirroring, RGW multisite configuration 등을 사용하여 데이터 복제 및 재해 복구 환경을 구축합니다.
Capacity planning: 클러스터의 용량 사용량을 예측하고, 필요한 용량을 계획합니다. ceph osd df, ceph df detail 명령어를 사용하여 현재 용량 사용량을 확인하고, 과거 데이터를 분석하여 미래 용량 요구량을 예측합니다.


https://tech.osci.kr/ceph-ansible%EB%A1%9C-ceph-%EA%B5%AC%EC%B6%95%ED%95%B4%EB%B3%B4%EA%B8%B0/
