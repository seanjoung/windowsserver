Ceph 클러스터 유지 및 신규 클러스터 구성, 트러블 슈팅
RKE2 클러스터 유지 및 개선, 운영 트러블 슈팅
Backing service (DB, massage queue) 구축 롼기
온프레미스 환경에 쿠버네티스 에 배보펀 서비스 모니터링 및 운영

Ceph 운영 시 흔히 발생하는 상황과 이에 대한 명령어 및 스크립트는 다음과 같습니다.

I. 클러스터 상태 및 상태 모니터링
전반적인 클러스터 상태 확인:

ceph status 또는 ceph -s: 클러스터의 상태(예: HEALTH_OK, HEALTH_WARN, HEALTH_ERR), 서비스 상태(모니터, 관리자, OSD, MDS, RGW), 데이터 사용량, 풀 정보 및 PG 상태에 대한 간략한 개요를 제공합니다. 관리자가 가장 먼저 실행하는 명령입니다.
ceph -w 또는 ceph --watch-warn: 클러스터 활동 및 이벤트를 지속적으로 감시하고 실시간 업데이트를 표시합니다. ceph --watch-warn은 특히 경고 메시지를 필터링합니다.
ceph health: 클러스터 상태 요약을 표시합니다.
ceph health detail: 클러스터가 HEALTH_OK가 아닌 경우 자세한 오류 정보를 제공합니다.
클러스터 사용량 통계 확인:

ceph df: Unix df 명령과 유사하게 총 스토리지 용량, 사용된 공간, 사용 가능한 공간 및 풀 간 사용량 분석을 보여줍니다.
ceph df detail: 할당량 및 압축 사용량을 포함한 풀 통계에 대한 자세한 정보를 제공합니다.
데몬 상태 모니터링:

ceph osd stat: OSD가 up(실행 중이고 연결 가능) 및 in(서비스 중)인지 확인합니다.
ceph mon stat: 선택 에포크 및 쿼럼을 포함한 모니터 데몬의 상태를 표시합니다.
ceph mgr stat: 관리자 데몬의 상태를 표시합니다.
ceph mds stat: CephFS 클러스터에서 메타데이터 서버(MDS)의 상태를 표시합니다.
II. OSD(객체 스토리지 데몬) 관리
OSD 상태 분석:

ceph osd tree: 모든 OSD, 해당 클래스, 가중치, 상태(업/다운, 인/아웃) 및 CRUSH 맵 내 위치의 계층적 보기를 표시합니다. 실패한 OSD와 해당 물리적 위치를 식별하는 데 중요합니다.
ceph osd df tree: CRUSH 트리와 함께 OSD 디스크 사용량을 제공합니다.
ceph osd utilization: OSD에서 사용량 요약(최대 및 최소)을 표시합니다.
ceph osd perf: 커밋 지연 시간과 같은 OSD 성능 메트릭을 확인합니다.
OSD 추가/제거:

ceph osd create: 클러스터에 새 OSD를 추가하는 데 사용됩니다.
ceph osd rm <osd-id>: CRUSH 맵에서 OSD를 제거합니다.
ceph osd out <osd-id>: 클러스터에서 OSD를 out으로 표시하여 Ceph에 해당 OSD에서 데이터를 마이그레이션하도록 신호를 보냅니다.
ceph osd in <osd-id>: 클러스터에서 OSD를 in으로 표시합니다.
ceph osd down <osd-id>: OSD를 down으로 표시합니다.
OSD 가중치 및 플래그 조정:

ceph osd crush reweight <osd-id> <weight>: 데이터 분포를 제어하기 위해 CRUSH 맵에서 OSD의 가중치를 조정합니다. 클러스터의 균형을 맞추거나 용량이 다른 OSD를 수용하는 데 유용합니다.
ceph osd set <flag> / ceph osd unset <flag>: 전역 OSD 플래그를 관리합니다. 일반적인 플래그는 다음과 같습니다.
noout: 유지 관리 중에 자주 사용되며, Ceph가 OSD가 실패할 때 out으로 표시하지 않도록 합니다.
nobackfill: 백필 작업을 비활성화합니다.
norecover: 복구 작업을 비활성화합니다.
norebalance: 재조정 작업을 비활성화합니다.
pauserd, pausewr: OSD에 대한 읽기 및 쓰기 요청을 일시 중지합니다.
ceph osd set-full-ratio <ratio>: 클러스터의 전체 비율을 설정합니다(예: 90%는 0.90).
ceph osd set-nearfull-ratio <ratio>: 클러스터의 거의 전체 비율을 설정합니다(예: 85%는 0.85).
III. 배치 그룹(PG) 관리
PG 상태 확인:

ceph pg dump: 모든 배치 그룹에 대한 자세한 통계를 제공합니다.
ceph pg stat: PG 상태 및 개수를 요약합니다.
ceph pg dump_stuck <state>: 특정 상태(예: inactive, unclean, stale)에 멈춰 있는 PG를 나열합니다.
ceph pg map <pg-id>: 특정 PG가 OSD에 매핑되는 방식을 보여줍니다.
PG 작업 관리:

ceph pg scrub <pg-id>: 데이터 무결성을 확인하기 위해 특정 PG에서 스크럽 작업을 시작합니다.
ceph pg deep-scrub <pg-id>: 더 철저한 데이터 무결성 검사를 위해 정밀 스크럽을 시작합니다.
ceph pg force-recovery <pg-id>: 지정된 PG에 대한 복구를 우선시합니다.
ceph pg force-backfill <pg-id>: 지정된 PG에 대한 백필을 우선시합니다.
ceph osd pool set <pool-name> pg_autoscale_mode <mode>: 지정된 풀(on, off, warn)에 대한 PG의 자동 크기 조정을 제어합니다.
IV. 풀 관리
풀 나열 및 검사:

ceph osd lspools: 구성된 모든 풀을 나열합니다.
ceph osd pool ls detail: 복제 크기, PG 번호 및 CRUSH 규칙을 포함한 풀에 대한 자세한 정보를 제공합니다.
ceph osd pool stats <pool-name>: 특정 풀에 대한 사용량 통계를 표시합니다.
rados df: RADOS 풀 사용량 요약을 제공합니다.
풀 생성 및 삭제:

ceph osd pool create <pool-name> <pg-num> [<pgp-num>] [replicated|erasure]: 새 풀을 생성합니다.
ceph osd pool delete <pool-name> [<pool-name> --yes-i-really-really-mean-it]: 풀을 삭제합니다. 참고: 풀을 삭제하려면 mon_allow_pool_delete가 true여야 합니다.
ceph osd pool rename <old-name> <new-name>: 풀의 이름을 바꿉니다.
풀 설정 구성:

ceph osd pool set <pool-name> <key> <value>: 복제 크기, min_size 또는 애플리케이션 연결과 같은 다양한 풀 매개변수를 설정합니다.
ceph osd pool get <pool-name> <key>: 풀의 구성 값을 검색합니다.
ceph osd pool set-quota <pool-name> max_objects <num> 또는 max_bytes <num>: 풀의 객체 또는 바이트에 대한 할당량을 설정합니다.

V. CRUSH 맵 관리
CRUSH 맵은 데이터가 OSD, 랙 및 기타 장애 도메인에 분산되는 방식을 정의합니다.

CRUSH 맵 보기:

ceph osd tree: CRUSH 계층 구조를 보여줍니다.
ceph osd crush dump: 전체 CRUSH 맵을 덤프합니다.
crushtool -d <컴파일된 맵> -o <디컴파일된 맵.txt>: 편집을 위해 CRUSH 맵 바이너리를 디컴파일합니다.
CRUSH 맵 요소 수정:

ceph osd crush add-bucket <버킷 이름> <버킷 유형>: CRUSH 맵에 새 버킷(예: 호스트, 랙, 행)을 추가합니다.
ceph osd crush move <버킷 이름> <유형>=<위치>: CRUSH 계층 구조 내에서 버킷을 이동합니다.
ceph osd crush set <osd-이름> <가중치> root=<루트> [<버킷 유형>=<버킷 이름> ...]: CRUSH 맵 내에 OSD를 추가하거나 이동합니다.
ceph osd crush set-device-class <클래스> <osd-이름>: CRUSH 규칙에서 사용할 수 있는 장치 클래스(예: ssd, hdd, nvme)를 OSD에 할당합니다.
VI. 인증 및 구성
액세스 및 구성 설정 관리.

인증:
ceph auth list: 클라이언트 및 데몬에 대한 모든 인증 키를 나열합니다.
ceph auth print-key <엔티티>: 특정 엔티티(예: client.admin, osd.0)에 대한 키를 인쇄합니다.
구성:
ceph config dump: 전체 클러스터 구성 데이터베이스를 덤프합니다.
ceph config set <누구> <옵션> <값>: 특정 데몬 또는 전체 클러스터에 대한 구성 옵션을 설정합니다.
ceph config get <누구> <옵션>: 구성 옵션을 검색합니다.
ceph tell <데몬 유형>.<id> config set <옵션> <값>: 특정 데몬에 대한 런타임 구성을 설정합니다.
VII. 재해 복구 및 문제 해결
장애 또는 불일치가 발생한 경우 특정 명령이 복구 및 진단에 도움이 됩니다.

일반적인 문제 해결:

ceph crash ls: 클러스터에 기록된 충돌 이벤트를 나열합니다.
ceph log last [n]: 클러스터 로그에서 마지막 n줄을 표시합니다.
ceph -c /경로/ceph.conf -k /경로/키링 <명령>: 기본이 아닌 구성 및 키링 경로를 지정합니다.
CephFS 복구(고급):

cephfs-journal-tool journal export <backup.bin>: 위험한 작업을 시도하기 전에 백업을 위해 CephFS 저널을 내보냅니다.
cephfs-journal-tool event recover_dentries summary: 손상된 저널에서 파일 메타데이터를 복구하려고 시도합니다.
cephfs-data-scan pg_files <경로> <pg-id> [...]: 손실된 데이터 PG의 영향을 받는 파일을 검색합니다.
ceph fs new <fs_name> <metadata_pool> <data_pool> --force --recover: 모니터 저장소 손실 후 기존 풀에서 CephFS 파일 시스템을 다시 만듭니다.
느리거나 멈춘 OSD 또는 PG 처리:

이러한 항목을 식별하는 것은 종종 ceph status, ceph osd tree 및 ceph pg dump_stuck으로 시작합니다.
ceph pg force-recovery 또는 ceph osd reweight와 같은 명령은 문제를 완화하는 데 도움이 될 수 있습니다.
VIII. 자동화 및 스크립팅
이러한 명령의 대부분은 자동화를 위해 스크립트에 통합될 수 있습니다.

셸 스크립팅: ceph 명령을 grep, awk, jq(ceph -s -f json 또는 ceph pg dump --format=json과 같은 명령의 JSON 출력용)와 파이프하여 특정 정보를 추출하거나 클러스터 상태에 따라 작업을 자동화할 수 있습니다.
ceph-volume: 이 도구는 특히 자동화된 설정에서 OSD 배포 및 관리에 사용되지만 종종 cephadm 또는 rook과 같은 오케스트레이터와 통합됩니다.
rados 명령: 벤치마킹 또는 특정 데이터 작업(rados bench, rados put, rados get)에 유용한 RADOS 객체 저장소와 직접 상호 작용하기 위한 저수준 유틸리티입니다.


###################################################################################################################


1. 상태 확인 및 모니터링:

간단한 상태 확인 스크립트(Bash):
bash
#!/bin/bash
HEALTH=$(ceph health)
if [ "$HEALTH" != 'HEALTH_OK' ]; then
    echo "Ceph 클러스터 상태가 정상이 아닙니다. $HEALTH"
    ceph health detail # 추가 정보 제공
    # 여기에 알림 메커니즘 추가(예: 이메일, Slack 알림)
else
    echo "Ceph 클러스터 상태가 정상입니다."
fi
OSD 및 사용량 모니터링(Bash):
bash
#!/bin/bash
echo "Ceph 클러스터 상태:"
ceph status
echo ""
echo "OSD 트리:"
ceph osd tree
echo ""
echo "OSD 디스크 사용량:"
ceph osd df
echo ""
echo "풀 통계:"
ceph df
2. 유지 관리 모드 스크립트:

유지 관리 시작/종료(Bash):
bash
#!/bin/bash
ACTION=$1 # "start" 또는 "stop"
if [ "$ACTION" = "start" ]; then
    echo "Ceph 클러스터 유지 관리 모드를 시작합니다..."
    ceph osd set noout
    ceph osd set nobackfill
    ceph osd set norecover
    echo "Ceph 유지 관리 플래그(noout, nobackfill, norecover)가 설정되었습니다."
elif [ "$ACTION" = "stop" ]; then
    echo "Ceph 클러스터 유지 관리 모드를 종료합니다..."
    ceph osd unset noout
    ceph osd unset nobackfill
    ceph osd unset norecover
    echo "Ceph 유지 관리 플래그가 해제되었습니다."
else
    echo "사용법: $0 [start|stop]"
    exit 1
fi
3. OSD 관리:

점진적 OSD 재가중치 부여(Python/Bash 조합): ceph-gentle-reweight와 같은 도구(일반적으로 커뮤니티 스크립트 저장소에서 찾을 수 있음)는 CRUSH 가중치를 점진적으로 조정하여 OSD를 천천히 비우고 성능 영향을 최소화할 수 있습니다. 이러한 스크립트는 일반적으로 Ceph CLI와 상호 작용하여 OSD 상태를 쿼리하고 가중치를 업데이트합니다.

OSD 추가(개념적 Bash - 단순화):

bash
#!/bin/bash
DEVICE="/dev/sdb"
HOST="ceph-node1"
echo "$HOST 호스트의 $DEVICE에 OSD를 추가합니다..."
# 이는 단순화된 표현입니다. 실제 시나리오에서는 cephadm 또는 Rook을 사용하는 것이 좋습니다.
# cephadm osd create --data $DEVICE # cephadm을 사용한 예
# 자세한 단계에는 디스크 준비, OSD 배포 및 CRUSH 맵에 추가가 포함됩니다.
echo "$DEVICE에 대한 OSD 배포가 시작되었습니다."
4. 풀 관리:

복제된 풀 생성(Bash):
bash
#!/bin/bash
POOL_NAME="my_replicated_pool"
PG_NUM=128
REPLICAS=3 # 기본 복제본 수
echo "$PG_NUM PG 및 $REPLICAS 복제본으로 복제된 풀 $POOL_NAME을 생성합니다."
ceph osd pool create $POOL_NAME $PG_NUM $PG_NUM replicated
ceph osd pool set $POOL_NAME size $REPLICAS
ceph osd pool application enable $POOL_NAME rbd # 예: RBD에 대해 활성화
echo "풀 $POOL_NAME이 성공적으로 생성되었습니다."


1. 심화된 아키텍처 이해 및 문제 해결:

CRUSH 맵 분석 및 조정: ceph osd crush dump, ceph osd tree, ceph osd crush rule ls, ceph osd crush rule dump 명령어를 사용하여 CRUSH 맵을 분석하고, 필요에 따라 rule을 수정하여 데이터 분산 및 복제 정책을 변경합니다. 예를 들어 특정 장애 도메인에 데이터가 편중되는 것을 방지하기 위해 rule을 조정할 수 있습니다.
OSD 관리 및 장애 복구: ceph osd ls, ceph osd df, ceph osd perf, ceph osd out, ceph osd in, ceph osd rm, ceph osd reweight 명령어를 사용하여 OSD 상태를 확인하고, 장애 발생 시 OSD를 제거하고 추가하며, 가중치를 조정하여 데이터 복제 및 복구를 관리합니다. OSD의 성능 문제를 파악하고 해결할 수 있어야 합니다.
MON 및 MGR 관리: ceph mon stat, ceph mon dump, ceph mgr dump, ceph mgr module ls 명령어를 사용하여 MON 및 MGR 상태를 확인하고, quorum 상태를 유지하며, 모듈을 관리합니다. MON 장애 복구 절차를 숙지하고, MGR을 통해 클러스터 상태를 모니터링하고 관리합니다.
2. 고급 Ceph 기능 활용:

Cache Tiering: SSD와 HDD를 함께 사용하여 성능과 용량을 최적화하는 Cache Tiering을 구성하고 관리합니다. ceph osd tier add, ceph osd tier remove, ceph osd tier cache-mode 명령어를 사용합니다. 캐시 적중률, 지연 시간 등을 모니터링하고 성능을 분석합니다.
Erasure Coding: 데이터 복제 대신 Erasure Coding을 사용하여 저장 공간 효율성을 높입니다. ceph osd pool set <pool-name> erasure_code_profile <profile-name> 명령어를 사용하여 pool에 Erasure Coding을 적용하고, ceph osd erasure-code-profile set <profile-name> <k=m=...> 명령어를 사용하여 profile을 설정합니다. Erasure Coding의 장단점을 이해하고 적절한 use case에 적용합니다.
QoS (Quality of Service): RBD 이미지 또는 CephFS에 QoS를 적용하여 특정 애플리케이션의 성능을 보장합니다. rbd QoS set, ceph fs subvolumegroup set 명령어를 사용합니다.
CephFS Snapshots 및 Quotas: ceph fs subvolume snapshot create, ceph fs subvolume snapshot ls, ceph fs subvolume snapshot rm, ceph fs quota set 명령어를 사용하여 CephFS 스냅샷 및 quota를 관리하고, 데이터 보호 및 용량 관리 정책을 구현합니다.
3. 성능 튜닝 및 최적화:

OSD 성능 튜닝: ceph osd crush tunables 명령어를 사용하여 CRUSH 맵의 튜닝 가능한 파라미터를 조정하고 데이터 분산을 최적화합니다. OSD의 file system, journal, data 디바이스를 분리하여 성능을 향상시키는 방법을 이해하고 적용합니다.
MON 및 MGR 성능 튜닝: MON 및 MGR의 설정을 조정하여 성능 병목 현상을 해결합니다. MON의 네트워크 설정, MGR 모듈 설정 등을 최적화합니다.
네트워크 설정 최적화: MTU, network bonding, multiple network interfaces 등을 설정하여 Ceph 클러스터의 네트워크 성능을 향상시킵니다.
4. Ceph 클러스터 업그레이드 및 관리:

업그레이드 절차: ceph versions, ceph osd upgrade 명령어를 사용하여 Ceph 클러스터를 업그레이드합니다. 업그레이드 절차를 숙지하고, 롤백 계획을 수립하여 안전하게 업그레이드를 수행합니다.
Multi-site deployments: 여러 지역에 Ceph 클러스터를 구축하고 관리합니다. RBD mirroring, RGW multisite configuration 등을 사용하여 데이터 복제 및 재해 복구 환경을 구축합니다.
Capacity planning: 클러스터의 용량 사용량을 예측하고, 필요한 용량을 계획합니다. ceph osd df, ceph df detail 명령어를 사용하여 현재 용량 사용량을 확인하고, 과거 데이터를 분석하여 미래 용량 요구량을 예측합니다.


https://tech.osci.kr/ceph-ansible%EB%A1%9C-ceph-%EA%B5%AC%EC%B6%95%ED%95%B4%EB%B3%B4%EA%B8%B0/
